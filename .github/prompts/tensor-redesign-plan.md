# Tensor Redesign Plan - é€šç”¨åŒ–è®¾è®¡æ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜åˆ†æ

### å½“å‰é—®é¢˜
1. **ç¡¬ç¼–ç åå¤„ç†**: `filter_yolo`, `filter_yolo_pose`, `filter_yolo_seg` ä¸“ä¸º Ultralytics YOLO æ¨¡å‹è®¾è®¡
2. **ç¼ºä¹é€šç”¨æ€§**: æ— æ³•æ”¯æŒå…¶ä»–è§†è§‰æ¨¡å‹ï¼ˆDINO, SAM, ViT, DETR, RT-DETR, ä¼ ç»Ÿæ£€æµ‹å™¨ç­‰ï¼‰
3. **æ‰©å±•æ€§å·®**: æ·»åŠ æ–°æ¨¡å‹éœ€è¦ä¿®æ”¹ C++ ä»£ç å¹¶é‡æ–°ç¼–è¯‘
4. **Luaçµæ´»æ€§ä¸è¶³**: Luaå±‚ç¼ºå°‘ç›´æ¥æ“ä½œtensorçš„èƒ½åŠ›ï¼ˆåˆ‡ç‰‡ã€ç´¢å¼•ã€reshapeç­‰ï¼‰

### è®¾è®¡ç›®æ ‡
1. **é€šç”¨æ€§**: æ”¯æŒä»»æ„è§†è§‰æ¨¡å‹çš„åå¤„ç†
2. **é«˜æ€§èƒ½**: C++ å®ç°æ ¸å¿ƒæ“ä½œï¼ˆé›¶æ‹·è´ã€SIMDä¼˜åŒ–ï¼‰
3. **çµæ´»æ€§**: Luaå±‚å¯ä»¥çµæ´»ç»„åˆæ“ä½œï¼Œå¿«é€Ÿé€‚é…æ–°æ¨¡å‹
4. **å‘åå…¼å®¹**: ä¿ç•™ç°æœ‰YOLOç‰¹åŒ–å‡½æ•°ä½œä¸ºconvenienceæ–¹æ³•

---

## ğŸ¯ æ ¸å¿ƒè®¾è®¡æ€è·¯

### 1. åˆ†å±‚æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Lua Layer (çµæ´»çš„åå¤„ç†é€»è¾‘)            â”‚
â”‚  - æ¨¡å‹ç‰¹å®šçš„åå¤„ç†è„šæœ¬                          â”‚
â”‚  - çµæ´»ç»„åˆåŸºç¡€æ“ä½œ                              â”‚
â”‚  - å¿«é€Ÿè¿­ä»£ï¼Œæ— éœ€é‡æ–°ç¼–è¯‘                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“â†‘ (LuaIntf)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     C++ Tensor Layer (é«˜æ€§èƒ½åŸºç¡€æ“ä½œ)            â”‚
â”‚  - é€šç”¨tensoræ“ä½œ (slice, reshape, transpose)   â”‚
â”‚  - æ•°å­¦è¿ç®— (element-wise, reduction)           â”‚
â”‚  - é›¶æ‹·è´è§†å›¾ (view, subview)                   â”‚
â”‚  - SIMDä¼˜åŒ– (argmax, softmax, etc.)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ“ä½œåˆ†ç±»

#### Level 1: åŸºç¡€å½¢çŠ¶æ“ä½œ (Essential)
- **ç´¢å¼•/åˆ‡ç‰‡**: `tensor[{0, slice(4, 84)}]` â†’ æå–ç‰¹å®šç»´åº¦
- **Reshape**: `tensor:reshape({1, 84, 8400})` â†’ æ”¹å˜å½¢çŠ¶ï¼ˆé›¶æ‹·è´ï¼‰
- **Transpose**: `tensor:transpose({0, 2, 1})` â†’ ç»´åº¦ç½®æ¢
- **View**: `tensor:view(start, end)` â†’ åˆ›å»ºå­è§†å›¾ï¼ˆé›¶æ‹·è´ï¼‰
- **Squeeze/Unsqueeze**: å¢å‡ç»´åº¦

#### Level 2: æ•°å­¦è¿ç®— (Performance-Critical)
- **Element-wise**: `add, sub, mul, div, max, min` 
- **Reduction**: `sum, mean, max, min, argmax, argmin` (æŒ‡å®šaxis)
- **Activation**: `sigmoid, softmax, exp, log`
- **æ¯”è¾ƒ**: `gt, lt, ge, le, eq` (è¿”å›mask)

#### Level 3: é«˜çº§æ“ä½œ (Convenience)
- **NMS**: é€šç”¨çš„NMSç®—æ³•ï¼ˆIoUè®¡ç®—ï¼‰
- **Gather**: æ ¹æ®ç´¢å¼•æ”¶é›†å…ƒç´ 
- **Concat/Split**: æ‹¼æ¥/åˆ†å‰²tensor
- **TopK**: è¿”å›å‰Kä¸ªå…ƒç´ 

#### Level 4: ä¸“ç”¨å‡½æ•° (Optional Legacy)
- ä¿ç•™ç°æœ‰çš„ `filter_yolo`, `filter_yolo_pose` ç­‰ä½œä¸ºå¿«æ·æ–¹æ³•
- æ ‡è®°ä¸º "convenience methods"ï¼Œå»ºè®®ç”¨æˆ·ä½¿ç”¨é€šç”¨æ“ä½œ

---

## ğŸ”§ API è®¾è®¡

### C++ Tensor API

```cpp
class Tensor {
public:
    // ========== æ„é€ /å±æ€§ ==========
    Tensor(std::vector<float>&& data, std::vector<int64_t> shape);
    Tensor(const float* data, size_t size, std::vector<int64_t> shape); // é›¶æ‹·è´æ„é€ 
    
    std::vector<int64_t> shape() const;
    int64_t ndim() const;
    int64_t size() const;
    int64_t size(int dim) const; // ç‰¹å®šç»´åº¦å¤§å°
    
    // ========== Level 1: å½¢çŠ¶æ“ä½œ ==========
    // åˆ‡ç‰‡ (æ”¯æŒè´Ÿç´¢å¼•ï¼Œæ”¯æŒçœç•¥)
    Tensor slice(int dim, int64_t start, int64_t end, int64_t step = 1);
    Tensor slice_multi(const std::vector<SliceSpec>& specs); // å¤šç»´åˆ‡ç‰‡
    
    // Reshape (é›¶æ‹·è´ï¼Œä»…æ”¹å˜shape_)
    Tensor reshape(const std::vector<int64_t>& new_shape);
    
    // Transpose (ä¼šäº§ç”Ÿæ•°æ®é‡æ’ï¼Œé™¤éæ˜¯ç®€å•è½¬ç½®å¯ä¼˜åŒ–)
    Tensor transpose(const std::vector<int>& dims);
    Tensor transpose(); // é»˜è®¤åè½¬æ‰€æœ‰ç»´åº¦
    
    // View (å­è§†å›¾ï¼Œé›¶æ‹·è´)
    Tensor view(int64_t offset, int64_t length);
    
    // Squeeze/Unsqueeze
    Tensor squeeze(int dim = -1);
    Tensor unsqueeze(int dim);
    
    // ========== Level 2: æ•°å­¦è¿ç®— ==========
    // Element-wise (æ”¯æŒbroadcasting)
    Tensor add(const Tensor& other);
    Tensor add(float scalar);
    Tensor sub(const Tensor& other);
    Tensor mul(const Tensor& other);
    Tensor div(const Tensor& other);
    
    // Reduction (axis=-1è¡¨ç¤ºæ‰€æœ‰ç»´åº¦)
    Tensor sum(int axis = -1, bool keepdims = false);
    Tensor mean(int axis = -1, bool keepdims = false);
    Tensor max(int axis = -1, bool keepdims = false);
    Tensor min(int axis = -1, bool keepdims = false);
    
    // Argmax/Argmin (è¿”å›ç´¢å¼•tensorï¼Œint64ç±»å‹)
    LuaIntf::LuaRef argmax_lua(lua_State* L, int axis = -1); // è¿”å›tableæˆ–å•å€¼
    LuaIntf::LuaRef argmin_lua(lua_State* L, int axis = -1);
    
    // Activation
    Tensor sigmoid();
    Tensor softmax(int axis = -1);
    Tensor exp();
    Tensor log();
    
    // æ¯”è¾ƒ (è¿”å›boolç±»å‹çš„mask tensor)
    Tensor gt(float threshold);
    Tensor lt(float threshold);
    Tensor ge(float threshold);
    Tensor le(float threshold);
    
    // ========== Level 3: é«˜çº§æ“ä½œ ==========
    // TopK (è¿”å› {values, indices} çš„Lua table)
    LuaIntf::LuaRef topk(lua_State* L, int k, int axis = -1, bool largest = true);
    
    // Gather (æ ¹æ®ç´¢å¼•æ”¶é›†å…ƒç´ )
    Tensor gather(int axis, const Tensor& indices);
    
    // Concat/Split
    static Tensor concat(const std::vector<Tensor>& tensors, int axis);
    std::vector<Tensor> split(int num_splits, int axis);
    
    // ========== Level 4: è¾…åŠ©æ–¹æ³• ==========
    // ç›´æ¥æ•°æ®è®¿é—® (for Lua)
    float get_item(const std::vector<int64_t>& indices);
    void set_item(const std::vector<int64_t>& indices, float value);
    
    // è½¬æ¢ä¸ºLua table (å°tensorç”¨ï¼Œè°ƒè¯•ç”¨)
    LuaIntf::LuaRef to_table(lua_State* L);
    
    // æ‰“å° (è°ƒè¯•ç”¨)
    std::string to_string(int max_elements = 10);
    
    // ========== Legacy æ–¹æ³• (æ ‡è®°ä¸ºå¯é€‰) ==========
    LuaIntf::LuaRef filter_yolo(lua_State* L, float conf_thres);
    // ... å…¶ä»–YOLOç‰¹åŒ–æ–¹æ³•
    
    // ========== å†…éƒ¨API ==========
    const float* data() const;
    float* data();
    
private:
    std::shared_ptr<std::vector<float>> data_;
    std::vector<int64_t> shape_;
    std::vector<int64_t> strides_; // æ–°å¢ï¼šæ”¯æŒéè¿ç»­tensor
    int64_t offset_; // æ–°å¢ï¼šæ”¯æŒé›¶æ‹·è´åˆ‡ç‰‡
    bool contiguous_; // æ–°å¢ï¼šæ ‡è®°æ˜¯å¦è¿ç»­
    
    // å†…éƒ¨è¾…åŠ©
    Tensor contiguous() const; // è½¬æ¢ä¸ºè¿ç»­tensor
    int64_t compute_offset(const std::vector<int64_t>& indices) const;
};
```

### Lua API ä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹ 1: YOLOv8 ç›®æ ‡æ£€æµ‹ (ç”¨é€šç”¨æ“ä½œå®ç°)
```lua
function Model.postprocess(outputs, meta)
    local output = outputs["output0"]  -- [1, 84, 8400]
    
    -- 1. åˆ‡ç‰‡æå–ä¸åŒéƒ¨åˆ†
    local boxes = output:slice(1, 0, 4)        -- [1, 4, 8400] (cx,cy,w,h)
    local scores = output:slice(1, 4, 84)      -- [1, 80, 8400] (class scores)
    
    -- 2. è½¬ç½®ä¸º [8400, 4] å’Œ [8400, 80]
    boxes = boxes:squeeze(0):transpose()       -- [8400, 4]
    scores = scores:squeeze(0):transpose()     -- [8400, 80]
    
    -- 3. æ‰¾åˆ°æ¯ä¸ªboxçš„æœ€å¤§ç±»åˆ«
    local max_scores, class_ids = scores:max(1)  -- [8400], [8400]
    
    -- 4. è¿‡æ»¤ä½ç½®ä¿¡åº¦
    local mask = max_scores:ge(Model.config.conf_thres)  -- [8400] bool mask
    local filtered_boxes = boxes:gather(0, mask)
    local filtered_scores = max_scores:gather(0, mask)
    local filtered_classes = class_ids:gather(0, mask)
    
    -- 5. NMS
    local keep_indices = utils.nms(filtered_boxes, filtered_scores, Model.config.iou_thres)
    
    -- 6. æ„é€ ç»“æœ
    local results = {}
    for i, idx in ipairs(keep_indices) do
        local box = filtered_boxes[idx]
        table.insert(results, {
            x = box[0] - box[2]/2,
            y = box[1] - box[3]/2,
            w = box[2],
            h = box[3],
            score = filtered_scores[idx],
            class_id = filtered_classes[idx],
            label = Model.config.labels[filtered_classes[idx] + 1]
        })
    end
    
    return results
end
```

#### ç¤ºä¾‹ 2: åˆ†ç±»æ¨¡å‹ (ResNet/ViT)
```lua
function ClassificationModel.postprocess(outputs)
    local logits = outputs["output"]  -- [1, 1000]
    
    -- Softmax
    local probs = logits:softmax(1)
    
    -- TopK
    local top5 = probs:topk(5)
    
    local results = {}
    for i = 1, 5 do
        table.insert(results, {
            class_id = top5.indices[i],
            label = IMAGENET_LABELS[top5.indices[i] + 1],
            confidence = top5.values[i]
        })
    end
    
    return results
end
```

#### ç¤ºä¾‹ 3: Segmentation æ¨¡å‹ (SAM/SegFormer)
```lua
function SegmentationModel.postprocess(outputs, meta)
    local logits = outputs["logits"]  -- [1, num_classes, H, W]
    
    -- Argmaxè·å–ç±»åˆ«
    local pred_classes = logits:argmax(1)  -- [1, H, W]
    
    -- è°ƒæ•´åˆ°åŸå§‹å›¾åƒå¤§å°
    pred_classes = pred_classes:squeeze(0)  -- [H, W]
    local resized = cv.resize_nearest(pred_classes, meta.orig_w, meta.orig_h)
    
    return resized:to_table()  -- è½¬æ¢ä¸ºLua tableè¿”å›
end
```

#### ç¤ºä¾‹ 4: ä¿æŒå‘åå…¼å®¹
```lua
-- æ–¹å¼1: ä½¿ç”¨legacyæ–¹æ³• (å¿«é€Ÿï¼Œä½†ä¸é€šç”¨)
local results = output:filter_yolo(0.25)

-- æ–¹å¼2: ä½¿ç”¨é€šç”¨æ“ä½œ (çµæ´»ï¼Œæ¨è)
local results = Model.postprocess_generic(output)
```

---

## ğŸ“ å®ç°ç»†èŠ‚

### 1. é›¶æ‹·è´è®¾è®¡
```cpp
// å†…éƒ¨æ•°æ®ç»“æ„
struct TensorImpl {
    std::shared_ptr<std::vector<float>> data;  // å…±äº«åº•å±‚æ•°æ®
    std::vector<int64_t> shape;
    std::vector<int64_t> strides;  // æ­¥é•¿ï¼Œæ”¯æŒéè¿ç»­
    int64_t offset;                // èµ·å§‹åç§»
    bool contiguous;               // æ˜¯å¦è¿ç»­
};

// åˆ‡ç‰‡ç¤ºä¾‹ (é›¶æ‹·è´)
Tensor Tensor::slice(int dim, int64_t start, int64_t end) {
    Tensor result;
    result.data_ = this->data_;  // å…±äº«æ•°æ®æŒ‡é’ˆ
    result.shape_ = compute_new_shape(dim, start, end);
    result.strides_ = this->strides_;
    result.offset_ = this->offset_ + start * strides_[dim];
    result.contiguous_ = (dim == shape_.size() - 1);  // æœ€åç»´åº¦åˆ‡ç‰‡ä»è¿ç»­
    return result;
}
```

### 2. SIMD ä¼˜åŒ–
```cpp
// ä½¿ç”¨OpenCVä¼˜åŒ–çš„æ“ä½œ
Tensor Tensor::sigmoid() {
    Tensor result(shape_);
    cv::Mat src(1, size(), CV_32F, (void*)data());
    cv::Mat dst(1, size(), CV_32F, result.data());
    
    cv::exp(-src, dst);
    dst = 1.0f / (1.0f + dst);
    
    return result;
}

// Argmaxä¼˜åŒ– (SIMD)
int64_t Tensor::argmax_impl(const float* data, int64_t size) {
    // ä½¿ç”¨SSE/AVXåŠ é€Ÿ
    #ifdef USE_AVX
        // AVXå®ç°
    #else
        // æ ‡é‡å®ç°
        return std::max_element(data, data + size) - data;
    #endif
}
```

### 3. Luaç»‘å®š
```cpp
void register_module(lua_State* L) {
    LuaBinding(L)
        .beginModule("lua_nn")
            .beginClass<Tensor>("Tensor")
                // æ„é€ 
                .addConstructor(...)
                
                // Level 1: å½¢çŠ¶æ“ä½œ
                .addFunction("slice", &Tensor::slice)
                .addFunction("reshape", &Tensor::reshape)
                .addFunction("transpose", 
                    static_cast<Tensor(Tensor::*)()>(&Tensor::transpose))
                
                // Level 2: æ•°å­¦è¿ç®—
                .addFunction("add", static_cast<Tensor(Tensor::*)(float)>(&Tensor::add))
                .addFunction("sum", &Tensor::sum)
                .addFunction("argmax", &Tensor::argmax_lua)
                .addFunction("sigmoid", &Tensor::sigmoid)
                .addFunction("softmax", &Tensor::softmax)
                .addFunction("gt", &Tensor::gt)
                
                // Level 3: é«˜çº§æ“ä½œ
                .addFunction("topk", &Tensor::topk)
                .addFunction("gather", &Tensor::gather)
                
                // è®¿é—®/è°ƒè¯•
                .addFunction("get", &Tensor::get_item)
                .addFunction("set", &Tensor::set_item)
                .addFunction("to_table", &Tensor::to_table)
                
                // Metamethods
                .addMetaFunction("__index", &Tensor::lua_index)
                .addMetaFunction("__newindex", &Tensor::lua_newindex)
                .addMetaFunction("__tostring", &Tensor::to_string)
                .addMetaFunction("__add", &Tensor::add)
                .addMetaFunction("__sub", &Tensor::sub)
                .addMetaFunction("__mul", &Tensor::mul)
            .endClass()
        .endModule();
}
```

---

## ğŸš€ è¿ç§»ç­–ç•¥

### Phase 1: åŸºç¡€æ“ä½œ (Week 1)
- [ ] å®ç° `slice`, `reshape`, `transpose`
- [ ] å®ç° `strides` å’Œé›¶æ‹·è´æœºåˆ¶
- [ ] æ·»åŠ åŸºç¡€æµ‹è¯•

### Phase 2: æ•°å­¦è¿ç®— (Week 2)
- [ ] å®ç° element-wise æ“ä½œ (`add`, `mul`, ç­‰)
- [ ] å®ç° reduction æ“ä½œ (`sum`, `mean`, `argmax`)
- [ ] å®ç° activation å‡½æ•° (`sigmoid`, `softmax`)
- [ ] SIMDä¼˜åŒ–å…³é”®è·¯å¾„

### Phase 3: é«˜çº§æ“ä½œ (Week 3)
- [ ] å®ç° `topk`, `gather`, `concat`
- [ ] é€šç”¨NMSç®—æ³• (ç§»è‡³ `lua_utils`)
- [ ] Broadcastingæ”¯æŒ

### Phase 4: é›†æˆä¸æµ‹è¯• (Week 4)
- [ ] ç”¨é€šç”¨æ“ä½œé‡å†™YOLOåå¤„ç†è„šæœ¬
- [ ] æ·»åŠ æ–°æ¨¡å‹ç¤ºä¾‹ (ResNetåˆ†ç±», SegFormeråˆ†å‰²)
- [ ] æ€§èƒ½å¯¹æ¯” (é€šç”¨æ“ä½œ vs ç‰¹åŒ–å‡½æ•°)
- [ ] æ–‡æ¡£æ›´æ–°

### å‘åå…¼å®¹
- ä¿ç•™ `filter_yolo` ç­‰å‡½æ•°ï¼Œä½†æ ‡è®°ä¸º **deprecated**
- åœ¨æ–‡æ¡£ä¸­æ¨èä½¿ç”¨é€šç”¨æ“ä½œ
- æä¾›è¿ç§»æŒ‡å—

---

## ğŸ“Š æ€§èƒ½è€ƒè™‘

### ä¼˜åŒ–ç­–ç•¥
1. **é›¶æ‹·è´**: ä½¿ç”¨ `shared_ptr` å’Œ `strides` å®ç°
2. **OpenCVåŠ é€Ÿ**: åˆ©ç”¨OpenCVçš„SIMDä¼˜åŒ–æ•°å­¦å‡½æ•°
3. **å»¶è¿Ÿæ±‚å€¼**: ç®€å•æ“ä½œï¼ˆå¦‚reshapeï¼‰ä»…æ”¹å˜å…ƒæ•°æ®
4. **ç¼“å­˜å‹å¥½**: è¿ç»­å†…å­˜è®¿é—®æ¨¡å¼
5. **å¹¶è¡ŒåŒ–**: å¤§tensorä½¿ç”¨OpenMPå¹¶è¡Œ

### æ€§èƒ½ç›®æ ‡
- åˆ‡ç‰‡/reshape: < 1Î¼s (é›¶æ‹·è´)
- Argmax (8400å…ƒç´ ): < 10Î¼s (SIMD)
- Softmax (1000å…ƒç´ ): < 20Î¼s (OpenCV)
- Transpose (8400x84): < 100Î¼s (ç¼“å­˜ä¼˜åŒ–)

---

## ğŸ“ ä½¿ç”¨åœºæ™¯æ‰©å±•

### æ”¯æŒçš„æ¨¡å‹ç±»å‹
1. **ç›®æ ‡æ£€æµ‹**: YOLOç³»åˆ—, DETR, RT-DETR, Faster R-CNN
2. **åˆ†ç±»**: ResNet, ViT, ConvNeXt, EfficientNet
3. **åˆ†å‰²**: SAM, SegFormer, DeepLab, Mask R-CNN
4. **å§¿æ€ä¼°è®¡**: HRNet, MediaPipe, MMPose
5. **å…³é”®ç‚¹æ£€æµ‹**: SuperPoint, DISK
6. **æ·±åº¦ä¼°è®¡**: MiDaS, DPT

### ç¤ºä¾‹ï¼šæ”¯æŒ RT-DETR
```lua
-- RT-DETR è¾“å‡º: {boxes: [1, 300, 4], scores: [1, 300, 80]}
function RTDETR.postprocess(outputs, meta)
    local boxes = outputs["boxes"]:squeeze(0)    -- [300, 4]
    local scores = outputs["scores"]:squeeze(0)  -- [300, 80]
    
    -- æ‰¾åˆ°æœ€å¤§ç±»åˆ«å’Œåˆ†æ•°
    local max_scores, class_ids = scores:max(1)  -- [300]
    
    -- è¿‡æ»¤
    local mask = max_scores:ge(0.3)
    local filtered_boxes = boxes:gather(0, mask)
    local filtered_scores = max_scores:gather(0, mask)
    local filtered_classes = class_ids:gather(0, mask)
    
    -- è½¬æ¢åæ ‡æ ¼å¼ (cxcywh -> xyxy)
    local x1 = filtered_boxes:slice(1, 0, 1) - filtered_boxes:slice(1, 2, 3) / 2
    local y1 = filtered_boxes:slice(1, 1, 2) - filtered_boxes:slice(1, 3, 4) / 2
    local x2 = filtered_boxes:slice(1, 0, 1) + filtered_boxes:slice(1, 2, 3) / 2
    local y2 = filtered_boxes:slice(1, 1, 2) + filtered_boxes:slice(1, 3, 4) / 2
    
    return build_results(x1, y1, x2, y2, filtered_scores, filtered_classes)
end
```

---

## âœ… æ€»ç»“

### ä¼˜åŠ¿
1. **é€šç”¨æ€§**: ä¸€å¥—APIæ”¯æŒæ‰€æœ‰è§†è§‰æ¨¡å‹
2. **çµæ´»æ€§**: Luaå±‚å¿«é€Ÿè¿­ä»£ï¼Œæ— éœ€é‡æ–°ç¼–è¯‘
3. **é«˜æ€§èƒ½**: C++å®ç°ï¼Œé›¶æ‹·è´ï¼ŒSIMDä¼˜åŒ–
4. **å¯ç»´æŠ¤æ€§**: ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ˜“äºæ‰©å±•
5. **å‘åå…¼å®¹**: ä¸ç ´åç°æœ‰ä»£ç 

### å¼€å‘ä¼˜å…ˆçº§
1. **P0**: åŸºç¡€å½¢çŠ¶æ“ä½œ (slice, reshape, transpose) - è§£é”åŸºæœ¬èƒ½åŠ›
2. **P1**: æ•°å­¦è¿ç®— (argmax, softmax, gt) - æ”¯æŒå¤§éƒ¨åˆ†æ¨¡å‹
3. **P2**: é«˜çº§æ“ä½œ (topk, gather) - æå‡æ˜“ç”¨æ€§
4. **P3**: æ€§èƒ½ä¼˜åŒ– (SIMD, å¹¶è¡Œ) - æå‡æ€§èƒ½
5. **P4**: ç‰¹åŒ–å‡½æ•°è¿ç§» - æ¸…ç†æŠ€æœ¯å€º

### ä¸‹ä¸€æ­¥
1. Reviewè®¾è®¡æ–¹æ¡ˆ
2. åˆ›å»ºæ–°çš„ `lua_nn.h` å¤´æ–‡ä»¶
3. å®ç° Phase 1 åŸºç¡€æ“ä½œ
4. ç¼–å†™å•å…ƒæµ‹è¯•
5. æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
