# 7.3 Example: Face Recognition Pipeline

**Mode**: Serial (Det → Align → Embed)

---

## Overview

```
┌─────────────────────────────────────────────────────────────────┐
│  Face Recognition Pipeline                                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Input: Image with faces                                        │
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Model 1: Face Detection                                 │    │
│  │   - Detect all faces in image                           │    │
│  │   - Output: bounding boxes + 5 landmarks                │    │
│  └─────────────────────────────────────────────────────────┘    │
│                        │                                        │
│                        ▼ N faces + landmarks                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Model 2: Face Alignment (optional, can be preprocessing)│    │
│  │   - Align face using 5-point landmarks                  │    │
│  │   - Affine transform to canonical position              │    │
│  │   - Output: aligned face 112×112                        │    │
│  └─────────────────────────────────────────────────────────┘    │
│                        │                                        │
│                        ▼ N aligned faces                        │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Model 3: Face Embedding                                 │    │
│  │   - Extract 512-dim face feature                        │    │
│  │   - Input: aligned face (batch)                         │    │
│  │   - Output: embedding vector                            │    │
│  └─────────────────────────────────────────────────────────┘    │
│                        │                                        │
│                        ▼                                        │
│  Output: [{bbox, landmarks, embedding}, ...]                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Model Specifications

| Model | Input Size | Output | Purpose |
|-------|------------|--------|---------|
| RetinaFace | 640×640 | boxes + 5 landmarks | Face detection |
| (Alignment) | - | 112×112 aligned | Geometric normalization |
| ArcFace | 112×112 | 512-dim embedding | Face feature extraction |

---

## Critical: Face Alignment

### Why Alignment is Essential

```
┌─────────────────────────────────────────────────────────────────┐
│  Alignment Importance                                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Without alignment:                                             │
│    - Pose variation degrades recognition                        │
│    - Different face sizes cause inconsistency                   │
│    - Recognition accuracy drops significantly                   │
│                                                                 │
│  With alignment:                                                │
│    - Faces normalized to canonical pose                         │
│    - Consistent eye positions (fixed coordinates)               │
│    - Recognition accuracy improves 10-20%                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 5-Point Landmarks

```
┌─────────────────────────────────────────────────────────────────┐
│  5-Point Landmark Definition                                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│              ┌───────────────────────────┐                      │
│              │         (2)               │                      │
│              │    ○           ○          │  1: left eye         │
│              │   (0)         (1)         │  2: right eye        │
│              │                           │  3: nose             │
│              │          ○                │  4: left mouth       │
│              │         (2)               │  5: right mouth      │
│              │                           │                      │
│              │      ○       ○            │                      │
│              │     (3)     (4)           │                      │
│              └───────────────────────────┘                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Alignment Transform

```
┌─────────────────────────────────────────────────────────────────┐
│  Alignment Affine Transform                                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Target landmarks (ArcFace standard, 112×112):                  │
│    left_eye:    (38.29, 51.70)                                  │
│    right_eye:   (73.53, 51.50)                                  │
│    nose:        (56.03, 71.74)                                  │
│    left_mouth:  (41.55, 92.37)                                  │
│    right_mouth: (70.73, 92.20)                                  │
│                                                                 │
│  Process:                                                       │
│    1. Estimate similarity transform (scale, rotate, translate)  │
│    2. Apply affine warp to original image                       │
│    3. Output: 112×112 aligned face                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Data Flow

### Stage 1: Face Detection

```
┌─────────────────────────────────────────────────────────────────┐
│  Face Detection Stage                                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Preprocess:                                                    │
│    Input:  ctx.image                                            │
│    Process:                                                     │
│      - Resize to 640×640 (or dynamic based on image)            │
│      - Normalize to [0,1]                                       │
│    Output: tensor [1, 3, 640, 640]                              │
│                                                                 │
│  Inference:                                                     │
│    RetinaFace → boxes, landmarks, scores                        │
│                                                                 │
│  Postprocess:                                                   │
│    - Filter by confidence threshold (0.5)                       │
│    - Apply NMS                                                  │
│    - Scale coordinates to original image                        │
│    Output: [{bbox, landmarks[5], score}, ...]                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Stage 2: Alignment + Embedding

```
┌─────────────────────────────────────────────────────────────────┐
│  Alignment & Embedding Stage                                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Note: Alignment can be part of preprocess or separate model    │
│                                                                 │
│  Preprocess (includes alignment):                               │
│    Input:  ctx.image + ctx.results.det (N faces with landmarks) │
│    Skip:   if N == 0, return nil                                │
│    Process (for each face):                                     │
│      - Get 5 landmarks from detection                           │
│      - Compute similarity transform to target landmarks         │
│      - Apply affine warp                                        │
│      - Output: 112×112 aligned face                             │
│      - Normalize (subtract mean, divide by std)                 │
│      - Stack all aligned faces                                  │
│    Output: tensor [N, 3, 112, 112]                              │
│                                                                 │
│  Inference:                                                     │
│    ArcFace model → [N, 512]                                     │
│                                                                 │
│  Postprocess:                                                   │
│    - L2 normalize each embedding                                │
│    Output: [[512-dim embedding], ...]                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Timing Analysis

### Per-Stage Timing

```
┌─────────────────────────────────────────────────────────────────┐
│  Timing Breakdown (N=3 faces)                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Stage 1: Face Detection                                        │
│    Preprocess:    8 ms                                          │
│    Inference:    12 ms (NPU)                                    │
│    Postprocess:   2 ms                                          │
│    Subtotal:     22 ms                                          │
│                                                                 │
│  Stage 2: Alignment + Embedding (batch=3)                       │
│    Preprocess:    6 ms (3× alignment)                           │
│    Inference:    10 ms (NPU, batch=3)                           │
│    Postprocess:   1 ms (L2 norm)                                │
│    Subtotal:     17 ms                                          │
│                                                                 │
│  Total:          39 ms → ~25 FPS                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Face Matching

### Similarity Computation

```
┌─────────────────────────────────────────────────────────────────┐
│  Face Matching (post-pipeline)                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Cosine Similarity:                                             │
│    similarity = dot(embed_a, embed_b)                           │
│    (embeddings are L2 normalized, so dot = cosine)              │
│                                                                 │
│  Thresholds (typical):                                          │
│    > 0.6: Same person (high confidence)                         │
│    > 0.4: Possibly same person                                  │
│    < 0.4: Different persons                                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 1:N Search (Face Database)

```
┌─────────────────────────────────────────────────────────────────┐
│  Face Database Search                                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Database: N registered faces                                   │
│    gallery = [[512-dim], [512-dim], ...]  shape: [N, 512]       │
│                                                                 │
│  Query: 1 probe face                                            │
│    probe = [512-dim]  shape: [1, 512]                           │
│                                                                 │
│  Search:                                                        │
│    similarities = probe @ gallery.T  shape: [N]                 │
│    best_match = argmax(similarities)                            │
│    best_score = similarities[best_match]                        │
│                                                                 │
│  Performance:                                                   │
│    1K gallery: < 1 ms                                           │
│    10K gallery: ~5 ms                                           │
│    100K gallery: ~50 ms (needs optimization)                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Output Format

### Final Result Structure

```
{
    frame_id: 789,

    faces: [
        {
            bbox: [x1, y1, x2, y2],
            landmarks: [[x,y], [x,y], [x,y], [x,y], [x,y]],
            score: 0.98,
            embedding: [0.12, -0.34, ...]  -- 512-dim
        },
        ...
    ]
}
```

### With Database Match

```
{
    frame_id: 789,

    faces: [
        {
            bbox: [...],
            landmarks: [...],
            score: 0.98,
            embedding: [...],

            -- After database search:
            match: {
                identity_id: "person_001",
                name: "John Doe",
                similarity: 0.72
            }
        },
        ...
    ]
}
```

---

## Use Cases

### Access Control

```
1. Detect face in camera frame
2. Extract embedding
3. Search against authorized personnel database
4. Grant/deny access based on match score
```

### Attendance System

```
1. Capture photo at check-in point
2. Run face pipeline
3. Match against employee database
4. Log attendance with timestamp and match confidence
```

### Photo Organization

```
1. Scan all photos in album
2. Extract all face embeddings
3. Cluster by similarity
4. Group photos by person
```

---

## Quality Considerations

### Face Quality Assessment

```
┌─────────────────────────────────────────────────────────────────┐
│  Quality Factors                                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. Face Size                                                   │
│     Minimum: 50×50 pixels for reliable recognition              │
│     Recommended: 112×112 or larger                              │
│                                                                 │
│  2. Pose Angle                                                  │
│     Yaw: ±45° acceptable, ±15° optimal                          │
│     Pitch: ±30° acceptable, ±10° optimal                        │
│     Roll: ±30° (corrected by alignment)                         │
│                                                                 │
│  3. Blur / Sharpness                                            │
│     Laplacian variance > 100: acceptable                        │
│                                                                 │
│  4. Illumination                                                │
│     Even lighting preferred                                     │
│     Avoid extreme shadows or overexposure                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Quality-Gated Processing

```
After detection, before embedding:
  - Check face size > threshold
  - Check landmark confidence
  - Optionally: check blur/pose

If low quality:
  - Skip embedding extraction
  - Return face with quality flag
```

---

## Memory Usage

```
┌─────────────────────────────────────────────────────────────────┐
│  Memory Budget                                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Model weights:                                                 │
│    RetinaFace:   ~30 MB                                         │
│    ArcFace:      ~120 MB (ResNet-100 backbone)                  │
│    or MobileFaceNet: ~4 MB (lighter option)                     │
│    Total:        ~35-150 MB                                     │
│                                                                 │
│  Runtime buffers (N=5 faces):                                   │
│    Det input:     1.2 MB                                        │
│    Det output:    0.5 MB                                        │
│    Aligned faces: 5× 0.15 MB = 0.75 MB                          │
│    Embeddings:    5× 2 KB = 10 KB                               │
│    Total:         ~2.5 MB                                       │
│                                                                 │
│  Face database (1K faces):                                      │
│    1000 × 512 × 4 bytes = 2 MB                                  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```
