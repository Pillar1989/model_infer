# 7.2 Example: Instance Segmentation Pipeline

**Mode**: Parallel-Sync (Det ∥ Seg → Fusion)

---

## Overview

```
┌─────────────────────────────────────────────────────────────────┐
│  Instance Segmentation Pipeline                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Input: Video frame                                             │
│                                                                 │
│         ┌─────────────────────────────────────────────────┐     │
│         │                                                 │     │
│         ▼                                                 ▼     │
│  ┌─────────────────────────┐       ┌─────────────────────────┐  │
│  │ Model 1: Detection      │       │ Model 2: Segmentation   │  │
│  │   (YOLO)                │       │   (DeepLabV3)           │  │
│  │                         │       │                         │  │
│  │ Output: bboxes + class  │       │ Output: semantic mask   │  │
│  └───────────┬─────────────┘       └───────────┬─────────────┘  │
│              │                                 │                │
│              │            PARALLEL             │                │
│              │                                 │                │
│              └────────────────┬────────────────┘                │
│                               │                                 │
│                         ══════╧══════                           │
│                          BARRIER                                │
│                         ══════╤══════                           │
│                               │                                 │
│                               ▼                                 │
│                    ┌─────────────────────┐                      │
│                    │  Fusion             │                      │
│                    │  boxes + mask       │                      │
│                    │  → instance masks   │                      │
│                    └──────────┬──────────┘                      │
│                               │                                 │
│                               ▼                                 │
│  Output: [{bbox, class, instance_mask}, ...]                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Model Specifications

| Model | Input Size | Output | Purpose |
|-------|------------|--------|---------|
| YOLO11n-seg | 640×640 | boxes + proto masks | Object detection |
| DeepLabV3 | 512×512 | semantic mask [H,W,C] | Semantic segmentation |

---

## Parallel Execution

### Why Parallel?

```
┌─────────────────────────────────────────────────────────────────┐
│  Serial vs Parallel Comparison                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Serial Execution:                                              │
│    Det (30ms) → Seg (45ms) → Fusion (5ms) = 80ms                │
│                                                                 │
│  Parallel Execution:                                            │
│    Det (30ms) ─┐                                                │
│                ├─ barrier ─ Fusion (5ms) = 50ms                 │
│    Seg (45ms) ─┘                                                │
│                                                                 │
│  Speedup: 80ms → 50ms (37% faster)                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### No Dependency

- Detection doesn't need segmentation output
- Segmentation doesn't need detection output
- Both can process the same frame simultaneously

---

## Data Flow

### Detection Branch

```
┌─────────────────────────────────────────────────────────────────┐
│  Detection Branch (Model 1)                                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Preprocess:                                                    │
│    Input:  ctx.image                                            │
│    Process:                                                     │
│      - Letterbox resize to 640×640                              │
│      - Normalize to [0,1]                                       │
│    Output: tensor [1, 3, 640, 640]                              │
│                                                                 │
│  Inference:                                                     │
│    YOLO-seg model → boxes + proto masks                         │
│                                                                 │
│  Postprocess:                                                   │
│    - Extract boxes and class scores                             │
│    - Apply NMS                                                  │
│    - Scale to original coordinates                              │
│    Output: [{bbox, class, score}, ...]                          │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Segmentation Branch

```
┌─────────────────────────────────────────────────────────────────┐
│  Segmentation Branch (Model 2)                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Preprocess:                                                    │
│    Input:  ctx.image                                            │
│    Process:                                                     │
│      - Resize to 512×512 (may differ from det)                  │
│      - Normalize with ImageNet mean/std                         │
│    Output: tensor [1, 3, 512, 512]                              │
│                                                                 │
│  Inference:                                                     │
│    DeepLabV3 model → [1, num_classes, 512, 512]                 │
│                                                                 │
│  Postprocess:                                                   │
│    - Argmax to get class per pixel                              │
│    - Resize mask to original image size                         │
│    Output: semantic_mask [H, W]                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Fusion Stage

```
┌─────────────────────────────────────────────────────────────────┐
│  Fusion: Boxes + Semantic Mask → Instance Masks                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Input:                                                         │
│    results.det = [{bbox, class, score}, ...]                    │
│    results.seg = semantic_mask [H, W]                           │
│                                                                 │
│  Process:                                                       │
│    For each detection:                                          │
│      1. Extract mask region within bbox                         │
│      2. Filter by class (keep only matching class pixels)       │
│      3. Optional: Apply GrabCut refinement                      │
│      4. Create binary instance mask                             │
│                                                                 │
│  Output:                                                        │
│    { instances: [{bbox, class, score, mask}, ...] }             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Timing Analysis

### Parallel Timing

```
┌─────────────────────────────────────────────────────────────────┐
│  Timing Diagram                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Time (ms):  0    10    20    30    40    50                    │
│              │     │     │     │     │     │                    │
│  Detection:  ├─────────────────────┤                            │
│              │  pre  │   infer  │post│                          │
│              │ 8ms   │   20ms   │2ms │ = 30ms                   │
│                                                                 │
│  Segment:    ├───────────────────────────────────────┤          │
│              │  pre   │      infer       │   post    │          │
│              │ 10ms   │      30ms        │   5ms     │ = 45ms   │
│                                                                 │
│  Barrier:                                            │          │
│                                                      ▼          │
│  Fusion:                                        ├────┤          │
│                                                 │ 5ms│          │
│                                                                 │
│  Total:      45ms (seg) + 5ms (fusion) = 50ms                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Hardware Requirements

| Scenario | Implementation | Timing |
|----------|----------------|--------|
| Single NPU core | Sequential within parallel phase | 30+45=75ms |
| Dual NPU cores | True parallel | max(30,45)=45ms |
| CPU + NPU | Det on NPU, Seg on CPU | max(30,80)=80ms |

---

## Fusion Strategies

### Strategy 1: Simple Crop

```
For each detection bbox:
    instance_mask = semantic_mask[y1:y2, x1:x2]
    instance_mask = (instance_mask == detection.class)
```

### Strategy 2: Class-Aware Filtering

```
For each detection:
    1. Get mask region within bbox
    2. Keep only pixels with matching class
    3. Apply morphological operations (open/close)
    4. Find largest connected component
```

### Strategy 3: GrabCut Refinement

```
For each detection:
    1. Initialize GrabCut with bbox as probable foreground
    2. Use semantic mask to guide foreground/background
    3. Run 3 iterations of GrabCut
    4. Output refined mask
```

---

## Output Format

### Final Result Structure

```
{
    frame_id: 456,

    instances: [
        {
            bbox: [x1, y1, x2, y2],
            class: 0,  -- person
            score: 0.95,
            mask: binary_mask [H, W]  -- or RLE encoded
        },
        {
            bbox: [x1, y1, x2, y2],
            class: 2,  -- car
            score: 0.88,
            mask: binary_mask [H, W]
        },
        ...
    ],

    -- Optional: keep intermediate results
    det: [...],      -- raw detections
    seg: mask [H,W]  -- semantic mask
}
```

---

## Use Cases

### Object Counting with Precise Boundaries

```
Instance masks enable:
  - Accurate object counting (no overlapping bbox issues)
  - Precise area measurement
  - Occlusion handling
```

### Video Editing / Background Removal

```
For each frame:
  - Run pipeline → instance masks
  - Composite: replace background where mask == 0
  - Output: foreground objects on new background
```

---

## Memory Usage

```
┌─────────────────────────────────────────────────────────────────┐
│  Memory Budget                                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Model weights:                                                 │
│    YOLO11n-seg:  ~15 MB                                         │
│    DeepLabV3:    ~40 MB                                         │
│    Total:        ~55 MB                                         │
│                                                                 │
│  Runtime buffers (1080p input):                                 │
│    Det input:    1.2 MB                                         │
│    Det output:   3 MB (boxes + protos)                          │
│    Seg input:    3 MB (512×512×3×4)                             │
│    Seg output:   2 MB (512×512×21×4)                            │
│    Semantic mask: 2 MB (1080×1920)                              │
│    Instance masks: N × 2 MB (if full resolution)                │
│    Total:        ~15-30 MB                                      │
│                                                                 │
│  Grand total:    ~70-85 MB                                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Comparison with Single Model Approaches

| Approach | Models | Pros | Cons |
|----------|--------|------|------|
| YOLO-seg only | 1 | Faster, simpler | Lower mask quality |
| Mask R-CNN | 1 | Good quality | Slower, heavier |
| Det ∥ Seg (this) | 2 | Flexible, modular | Fusion complexity |
| SAM + Det | 2 | Best quality | Very slow |
